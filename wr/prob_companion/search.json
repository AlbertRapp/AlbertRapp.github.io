[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Übungsbegleiter",
    "section": "",
    "text": "Vorwort\nDieser Aufschrieb soll als Begleitinformationen zu den Übungsblättern verstanden werden. Ziel ist es, Inhalte aus den Übungen tiefer zu beleuchten als es das Vorrechnen im regulären Übungsbetrieb erlaubt. Insbesondere versuche ich neben dem rigorosen mathematischen Verständnis aus den Übungsaufgaben ein “intuitives” und weniger formellastiges Verständnis zu fördern.\nGemäß der Natur der Sache müssen einige Inhalte aus dem Skript wiederholt werden. Dennoch kann und soll dieser Aufschrieb das Vorlesungsskript (Spodarev 2020) bzw. die ältere, aber nicht ganz deckungsgleiche Version (Spodarev 2018) nicht ersetzen. Ebenso ist dies nicht als eine Art Zusammenfassung der “wichtigen Prüfungsinhalte” zu verstehen. Es ist lediglich mein Anliegen, einzelne grundlegende Aspekte auf eine weniger formale Weise zu beleuchten, da diese Dinge - meiner Erfahrung nach - notgedrungen durch Zeitmangel und Stoffdichte oftmals im Vorlesungs- und Übungsbetrieb zu kurz kommen.\nIn den vergangenen Semester habe ich versucht, diese Informationen über zusätzliche Folien in den Übungen darzustellen. Damit diese sich allerdings auch ohne meinen zugehörigen Vortrag als Lernunterlage eignen, musste ich einige Inhalte in Textform auf den Folien beschreiben. Ich habe zwar versucht, Texte in den Folien auf ein Minimum zu beschränken, dennoch musste ich - zu meinem eigenen Unwohl - feststellen, dass ich für meinen Geschmack immer noch zu viel Text auf den Folien einbringen musste.\nIch bin einer der größten Kritiker an Vorträgen mit vollgeschriebenen Folien. Leider sind solche Vorträge meiner Erfahrung nach leider eher die Norm als die Ausnahme. Daher bin ich erfreut darüber, diesen Übungsbegleiter als Lernunterlage aushändigen und meine Übungsfolien dadurch schlanker gestalten zu können.\nOb der Übungsbegleiter letztendlich eine sinnvolle Ergänzung zum Übungsbetrieb darstellt, dürft ihr als Übungsteilnehmer selbst entscheiden. Ich bin für Feedback immer offen und nehme auch Kritik (insbesondere bzgl. zu starken Ungenauigkeiten durch die umgangssprachliche Beschreibung mathematischer Inhalte) gerne an. Ihr dürft euch per Mail oder Übungsfeedback im Moodle immer mit euren Anregungen melden.\nAbschließend möchte ich mich an dieser Stelle herzlichst bei Jun.-Prof. Dr. Marco Oesting für die aufmerksame Korrektur dieses Textes bedanken.\n\n\n\n\nSpodarev, Evgeny. 2018. Vorlesungsskript zur Elementaren Wahrscheinlichkeitsrechnung und Statistik.\n\n\n———. 2020. Vorlesungsskript zur Elementaren Wahrscheinlichkeitsrechnung und Stastistik."
  },
  {
    "objectID": "01_Wahrscheinlichkeitsmasse_Mengensysteme.html",
    "href": "01_Wahrscheinlichkeitsmasse_Mengensysteme.html",
    "title": "1  Wahrscheinlichkeitsmaße und Mengensysteme",
    "section": "",
    "text": "Das stochastische Grundgerüst in einem Grundraum \\(E\\) basiert auf Mengen bzw. Ereignissen in einem Wahrscheinlichkeitsraum, der als ein Tripel \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) definiert ist, das die Menge von Elementarereignissen bzw. die Grundmenge \\(\\Omega \\subset E\\) mit einer \\(\\sigma\\)-Algebra \\(\\mathcal{F}\\) und einem Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\) kombiniert. Dabei sind die zwei hier noch unbekannten Begriffe definiert durch\n\nDefinition 1.1 (\\(\\sigma\\)-Algebra) Ein Mengensystem \\(\\mathcal{F} \\subset \\mathcal{P}(\\Omega)\\) heißt \\(\\sigma\\)-Algebra, wenn alle drei der folgenden Bedingungen erfüllt sind:\n\nEs gilt \\(\\emptyset \\in \\mathcal{F}\\).\nFalls \\(A \\in \\mathcal{F}\\), so gilt auch \\(A^c \\in \\mathcal{F}\\).\nFalls \\(A_1, A_2, \\ldots \\in \\mathcal{F}\\) so gilt auch \\(\\cup_{n \\in \\mathbb{N}} A_n \\in \\mathcal{F}\\).\n\n\n\nDefinition 1.2 (Wahrscheinlichkeitsmaß) Sei \\(\\mathcal{F}\\) eine \\(\\sigma\\)-Algebra auf \\(\\Omega\\). Eine Mengenfunktion \\(\\mathbb{P}: \\mathcal{F} \\rightarrow \\mathbb{R}\\) heißt Wahrscheinlichkeitsmaß auf \\((\\Omega, \\mathcal{F})\\), wenn\n\n\\(\\mathbb{P}(A) \\in [0, 1]\\) für alle \\(A \\in \\mathcal{F}\\),\n\\(\\mathbb{P}(\\Omega) = 1\\) und\nFalls \\(A_1, A_2, \\ldots \\in \\mathcal{F}\\) paarweise disjunkt sind, so gilt \\[\\begin{align*}\n  \\mathbb{P} \\bigg( \\bigcup_{n = 1}^{\\infty} A_n \\bigg)\n  =\n  \\sum_{n = 1}^{\\infty} \\mathbb{P}(A_n).\n\\end{align*}\\]\n\n\nDie \\(\\sigma\\)-Algebra dient dabei als Sammelsurium von Mengen, denen wir eine Wahrscheinlichkeit zuordnen können und die wir daher als messbar bezeichnen. Der zentrale Punkt, warum wir das Konstrukt der \\(\\sigma\\)-Algebra brauchen und uns bei dem zugrundeliegenden Mengensystem nicht mit der Potenzmenge \\(\\mathcal{P}(\\Omega)\\) begnügen können, ist der Satz von Vitali. Grob formuliert besagt dieser, dass es Mengen gibt, die nicht messbar sind, d.h. diesen Mengen kann man kein sinnvolles Maß/Volumen zuordnen.\nStattdessen beschränkt man sich auf einige wenige Axiome, die messbare Mengen erfüllen sollten und landet damit bei der Definition der \\(\\sigma\\)-Algebra, deren Bedingungen sich aus stochastischer Perspektive übersetzen lassen als\n\nEinem unmöglichen Ereignis kann man eine Wahrscheinlichkeit zuordnen.\nFalls man einem Ereignis eine Wahrscheinlichkeit zuordnen kann, so kann man auch dem Gegenereignis eine Wahrscheinlichkeit zuordnen.\nLassen sich einer abzählbaren Anzahl von Ereignissen jeweils eine Wahrscheinlichkeit zuordnen, so lässt sich auch dem Ereignis, dass irgendeines dieser Ereignisse eintritt, eine Wahrscheinlichkeit zuordnen.\n\nBei den bisherigen Überlegungen haben wir lediglich die Tatsache untersucht, ob man eine Wahrscheinlichkeit zuordnen kann und haben auf diese Weise die \\(\\sigma\\)-Algebra beleuchtet. Jedoch kann man mit der \\(\\sigma\\)-Algebra alleine keine sinnvolle Aussage über die Höhe der Wahrscheinlichkeit eines Ereignisses treffen.\nDafür benötigen wir eine Funktion, die genau diese Aufgabe erledigt und auch hier gehen wir wieder axiomatisch vor, damit die entsprechende Funktion möglichst intuitive Eigenschaften besitzt. Gerade diese Eigenschaften finden sich in der Definition des Wahrscheinlichkeitsmaßes und lassen sich wieder aus stochastischer Perspektive übersetzen als\n\nJede Wahrscheinlichkeit liegt zwischen \\(0\\) und \\(1\\).\nDie Wahrscheinlichkeit, dass irgendetwas passiert ist 1.\nFalls man beliebig viele Ereignisse betrachtet, die nicht gleichzeitig eintreten können, so ergibt sich die Wahrscheinlichkeit für das Ereignis, dass eins dieser Ereignisse eintritt, als die Summe der Wahrscheinlichkeiten der einzelnen Ereignisse.\n\nBetrachten wir nun zwei elementare Wahrscheinlichkeitsräume.\n\nBeispiel 1.1 Sei \\(\\Omega \\subset \\mathbb{R}\\) und \\(A\\) eine nichtleere Teilmenge von \\(\\Omega\\). Dann ist \\((\\Omega, \\{ \\emptyset, \\Omega, A, A^c \\}, \\mathbb{P})\\) mit \\[\\begin{align*}\n           \\mathbb{P}(B) = \\begin{cases}\n               0 &, B = \\emptyset \\\\\n               1 &, B = \\Omega \\\\\n               p&, B = A \\\\\n               1 - p &,B = A^c\n           \\end{cases}\n\\end{align*}\\]\nein Wahrscheinlichkeitsraum, falls \\(p \\in [0,1]\\).\n\n\nBeispiel 1.2 (Borelsche \\(\\sigma\\)-Algebra) Es sei \\(\\mathcal{B}([0,1])\\) die Borel-\\(\\sigma\\)-Algebra auf \\([0,1]\\). Grob (und sehr vereinfacht) gesagt beinhaltet die Borel-\\(\\sigma\\)-Algebra fast alle Mengen, die irgendwie von Interesse sein könnten,. In diesem Fall beschränken wir uns dabei auf Teilmengen aus dem Intervall \\([0, 1]\\). Zeitgleich sind diese Mengen so “gutartig”, dass man ihnen einen Volumen bzgl. des Lebegue-Maßes \\(\\lambda\\) zuordnen kann.\nDas Lebesgue-Maß ist hierbei ein elementares Maß, das einem Intervall dessen Länge als Maß zuordnet, d.h. \\(\\lambda([a, b]) = b - a\\) für alle \\(a < b\\). Es gilt nun, dass \\(( [0,1],~\\mathcal{B}([0,1]),~\\lambda)\\) ein Wahrscheinlichkeitsraum ist."
  },
  {
    "objectID": "02_Bed_Wsk_und_Bayes.html",
    "href": "02_Bed_Wsk_und_Bayes.html",
    "title": "2  Bedingte Wahrscheinlichkeit und der Satz von Bayes",
    "section": "",
    "text": "Idealerweise ist ein medizinischer Test immer zu 100% zuverlässig. Allerdings wissen wir aus der Praxis, dass es immer wieder zu falsch-positiven oder falsch-negativen Testergebnissen in der Medizin kommt. Das beste worauf wir also hoffen können, ist das ein Test mit sehr großer Wahrscheinlichkeit richtig liegt. Somit sollte ein Test so gestaltet sein, dass die Wahrscheinlichkeit, dass ein Patient tatsächlich krank ist, wenn der Test dies anzeigt, sehr groß ist.\nIntuitiv ist das alles sehr einleuchtend. Allerdings sollten wir das auch noch mathematisch formal präzisieren. Offensichtlich können wir die gesuchte Wahrscheinlichkeit nicht einfach mit \\(\\mathbb{P}(K)\\) bezeichnen, wobei \\(K\\) für das Ereignis steht, dass ein zufällig ausgewählter Mensch krank ist. Schließlich haben wir zusätzliche Information. Unser Test war ja positiv. Dementsprechend würden wir erwarten, dass es nun wahrscheinlicher ist, dass der Patient krank.\nEin naiver Ansatz wäre nun also zu vermuten, dass die gesuchte Wahrscheinlichkeit \\(\\mathbb{P}(K \\cap T)\\) entspricht, wobei \\(T\\) dem Ereignis “Test positiv” und der Schnitt der Mengen dem Ereignis “Beide Ereignisse eingetreten” entspricht. Offensichtlich stellt man schnell fest, dass \\(\\mathbb{P}(K \\cap T) \\leq \\mathbb{P}(K)\\), was wiederum bedeuten würde, dass wir es für weniger wahrscheinlich halten, krank zu sein, nachdem der Test positiv ausgefallen ist. Das kann nicht unserer Intuition entsprechen.\nAllerdings können wir uns überlegen, dass wir zusätzlich zu unseren vorherigen Überlegung den Grundraum auf die Fälle einschränken können, in denen \\(T\\) wahr ist. In diesem Fall muss ich die Wahrscheinlichkeit \\(\\mathbb{P}(K \\cap T)\\) nur noch entsprechend der Wahrscheinlichkeit des neuen Grundraumes normieren, was uns die gesuchte Wahrscheinlichkeit \\(\\mathbb{P}(K \\cap T)/\\mathbb{P}(T)\\) liefert und zur allgemeinen Definition der bedingten Wahrscheinlichkeit führt.\n\nDefinition 2.1 (Bedingte Wahrscheinlichkeit) Es seien \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum und \\(A, B \\in \\mathcal{F}\\) seien zwei Ereignisse, wobei \\(\\mathbb{P}(B) > 0\\). Dann ist die bedingte Wahrscheinlichkeit von \\(A\\) unter der Bedingung \\(B\\) definiert als \\[\\begin{align*}\n    \\mathbb{P}(A \\vert B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}.\n\\end{align*}\\]\n\nIn diesem Zusammenhang bietet es sich auch an, dass Konzept von Unabhängigkeit zu erwähnen. Intuitiv ergibt es Sinn zwei Ereignisse als (stochastisch) unabhängig voneinander zu betrachen, wenn die Wahrscheinlichkeit, dass beide Ergebnisse eintreten, sich als Produkt der beiden Einzelwahrscheinlichkeiten ergibt. Formal definieren wir\n\nDefinition 2.2 (Unabhängigkeit) Es seien \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum und \\(A, B \\in \\mathcal{F}\\) seien zwei Ereignisse. Die Ereignissee \\(A, B\\) sind genau dann unabhängig, falls \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\).\n\nVerknüpft man dies mit Definition 2.1 so stellt man fest, dass für unabhängige Mengen \\(A, B\\) gilt, dass \\(\\mathbb{P}(A \\vert B) = \\mathbb{P}(A)\\) und \\(\\mathbb{P}(B) = \\mathbb{P}(B \\vert A)\\). In der Praxis stellt man oft fest, dass wir zwar an einer bedingten Wahrscheinlichkeit \\(\\mathbb{P}(A \\vert B)\\) interessiert sind, aber nur die Wahrscheinlichkeit \\(\\mathbb{P}(B \\vert A)\\) messen können.\n\nBeispiel 2.1 Aus medizinischen Studien wissen wir, dass Rauchen das Risiko erhöht, an Lungenkrebs zu erkranken. Die untersuchte Größe ist hier also \\(\\mathbb{P}(K \\vert R)\\), wobei \\(K\\) für das Ereignis “Patient hat Krebs” und \\(R\\) für das Ereignis “Patient ist Raucher” steht. Jedoch können wir in Studien nur Krebspatienten als Raucher bzw. Nichtraucher identifizieren, d.h. durch unsere Beobachtungen erhalten wir nur Aufschluss über die Wahrscheinlichkeit \\(\\mathbb{P}(R \\vert K)\\).\n\nUm dennoch die gesuchte Größe zu berechnen, hilft uns der Satz von Bayes.\n\nTheorem 2.1 (Bayes) Es sei \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum und \\(A, B \\in \\mathcal{F}\\) zwei Ereignisse mit \\(\\mathbb{P}(A), \\mathbb{P}(B) > 0\\). Dann gilt \\[\\begin{align*}\n    \\mathbb{P}(A \\vert B) = \\frac{\\mathbb{P}(A) \\mathbb{P}(B \\vert A)}{\\mathbb{P}(B)}.\n\\end{align*}\\]\n\nSomit stellt der Satz von Bayes, benannt nach dem Pfarrer Thomas Bayes, fest, dass die bedingten Wahrscheinlichkeiten proportional zueinander sind, wenn man Bedingung und zu untersuchendes Ereignis miteinander vertauscht. Zugleich liefert der Satz von Bayes den passenden Proportionalitätsfaktor dazu.\nEin letztes nützliches Werkzeug in diesem Zusammenhang ist der Satz über die totale Wahrscheinlichkeit. Dieser ermöglicht es, die Wahrscheinlichkeit eines Ereignisses durch die Zerlegung des Grundraumes als gewichtetes Mittel der zugehörigen bedingten Wahrscheinlichkeiten zu berechnen.\n\nTheorem 2.2 (Totale Wahrscheinlichkeit) Es sei \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum und \\(A, B_1, B_2, \\ldots\\) seien Ereignisse mit \\(\\mathbb{P}(B_i) > 0\\) für alle \\(i \\in \\mathbb{N}\\). Außerdem sind die \\(B_i\\) paarweise disjunkt und \\(\\cup_{i \\in \\mathbb{N}} B_i = \\Omega\\). Dann gilt \\[\\begin{align*}\n        \\mathbb{P}(A) = \\sum_{i = 1}^{\\infty} \\mathbb{P}(A \\vert B_i)\\mathbb{P}(B_i).\n    \\end{align*}\\]\n\nNach dem Satz von Bayes gilt \\(\\mathbb{P}(A \\vert B) \\approx \\mathbb{P}(B \\vert A)\\) genau dann, wenn \\(\\mathbb{P}(A) \\approx \\mathbb{P}(B)\\). Das heißt im Allgemeinen ist es nicht möglich, die bedingte Wahrscheinlichkeit zu invertieren. Dennoch passiert diese Fehleinschätzung im Alltag so häufig, dass dieser logische Fehler auch als “Verwechslung der Umgekehrung”, “Umkehrungsfehlschluss” oder “Trugschluss des Anklägers” bekannt ist. Eins der bekanntesten Beispiele dafür beruht dabei auf einer Studie mit 100 Ärzten in der folgendes Fallbeispiel durchgespielt wurde:\n\nBeispiel 2.2 ((Eddy 1982)) Eine Patientin hat einen Knoten in der Brust woraufhin eine Mammographie durchgeführt wurde deren Befund zurückliefert, dass die Patienten einen bösartigen Tumor hat. Weiterhin sei bekannt, dass\n\n1% aller Brusttumore bösartig sind.\nMammographien einen bösartigen Tumor in 80 % der Fälle als solchen erkennen und in den sonstigen Fällen als gutartig einstufen.\nMammographien einen gutartigen Tumor in 90 % der Fälle als solchen erkennen und in den übrigen Fällen als bösartig einstufen.\n\nGesucht ist nun die bedingte Wahrscheinlichkeit \\(\\mathbb{P}(B \\vert P)\\), dass \\(B = \\text{``Tumor ist bösartig''}\\) gegeben \\(P = \\text{``Test auf bösartigen Tumor ist positiv''}\\). In der Studie haben fast alle der Ärzte diese Wahrscheinlichkeit auf ungefähr 75 % geschätzt und liegen damit sehr nahe an \\(\\mathbb{P}(P \\vert B) = 80 \\%\\). Die echte Wahrscheinlichkeit liefert der Satz von Bayes zusammen mit dem Satz der totalen Wahrscheinlichkeit als \\[\\begin{align*}\n    \\mathbb{P}(B \\vert P)\n    &=\n    \\frac{\\mathbb{P}(B) \\mathbb{P}(P \\vert B)}{\\mathbb{P}(P)}\\\\\n    &=\n    \\frac{\\mathbb{P}(B) \\mathbb{P}(P \\vert B)}{\n        \\mathbb{P}(P \\vert B) \\mathbb{P}(B) + \\mathbb{P}(P \\vert B^c) \\mathbb{P}(B^c)\n    }\\\\\n    &=\n    \\frac{0.01 \\cdot 0.80}{0.80 \\cdot 0.01 + 0.1 \\cdot 0.99}\n    =\n    0.0748.\n\\end{align*}\\]\n\n\nAnmerkung. Das vorangegangene Beispiel wurde als Verdeutlichung für logische Trugschlüsse aufgeführt. Aus aktuellen Anlässen sei an dieser Stelle erwähnt, dass aus diesem fiktiven Beispiel keine Rückschlüsse auf aktuelle medizinische Praxis in Bezug auf Mammographien oder sonstige Untersuchungen möglich ist.\n\n\n\n\n\nEddy, David M. 1982. „Probabilistic reasoning in clinical medicine: Problems and opportunities“. In Judgment under Uncertainty: Heuristics and Biases, herausgegeben von Daniel Kahneman, Paul Slovic, und AmosEditors Tversky, 249–67. Cambridge University Press. https://doi.org/10.1017/CBO9780511809477.019."
  },
  {
    "objectID": "03_Zufallsvariablen.html",
    "href": "03_Zufallsvariablen.html",
    "title": "3  Zufallsvariablen",
    "section": "",
    "text": "Im Jahr 1901 hat der italienische Mathematiker Mario Lazzarini das Buffonsche Nadelexperiment durchgeführt, um \\(\\pi\\) zu approximieren. Angeblich baute er dafür eine Maschine, um eine Nadel 3408 mal zu werfen und zu zählen, wie oft die Nadel so fällt, dass sie ein Gitter aus parallelen Linien kreuzt.\nDie theoretischen Grundlagen des Experiments sind unumstritten, jedoch werden Lazzarinis Ergebnisse teilweise bezweifelt1. Hauptkritik besteht in der Frage, ob die Anzahl der Versuche gerade so gewählt wurde, um die damalige Approximation \\(\\pi \\approx \\frac{355}{113}\\) möglichst gut zu treffen. Außerdem wird daran gezweifelt, ob die Nadelwurfmaschine tatsächlich existierte und die Nadelwürfe überhaupt stattgefunden haben.\nLetztendlich ist es für uns egal, ob Lazzarini die Nadel (selber) geworfen hat oder nicht. Interessant ist an dieser Stelle dennoch, dass der komplette Versuchsaufbau darauf ausgelegt ist, lediglich eine Zahl \\(X\\) zu ermitteln. Diese Zahl soll uns angeben, wie oft die Nadel das Liniengitter gekreuzt hat. Auf gewisse Weise fasst diese Zahl \\(X\\) den relevanten Teil des Experimentes zusammen und lässt alle irrelevanten Informationen wie z.B. die genaue Nadelposition fallen2. Damit diese Zusammenfassung eines Zufallsexperiments durch eine Variable auf einer fundierten mathematischen Basis steht, müssen wir dies sauber definieren.\n\nDefinition 3.1 (Zufallsvariable) Es sei \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum. Dann heißt die Abbildung \\(X: \\Omega \\rightarrow \\mathbb{R}\\) Zufallsvariable, falls sie messbar bzgl. der Borel-\\(\\sigma\\)-Algebra \\(\\mathcal{B}(\\mathbb{R})\\) ist, d.h. \\[\\begin{align*}\n        X^{-1}(B) = \\{ \\omega \\in \\Omega \\vert X(\\omega) \\in B \\} \\in \\mathcal{F}.\n    \\end{align*}\\] für alle \\(B \\in \\mathcal{B}(\\mathbb{R})\\).\n\nWie eben erwähnt ist eine Zufallsvariable also einfach eine Funktion, die ein Zufallsexperiment / Ereignis aus dem Grundraum nimmt und diesem Versuchsausgang eine reelle Zahl zuweist. Die einzige Bedingung, die wir zusätzlich stellen, ist die Existenz der Wahrscheinlichkeit \\(\\mathbb{P}(X \\in B)\\) für alle \\(B \\in \\mathcal{B}(\\mathbb{R})\\), d.h. egal welchen Wert die Zufallsvariable annimmt, die Wahrscheinlichkeit, dass dies passiert, ist wohldefiniert. Diese Wohldefiniertheit wird dadurch gesichert, dass die zugehörige Menge in der \\(\\sigma\\)-Algebra \\(\\mathcal{F}\\) enthalten ist.\n\nAnmerkung. Falls uns mehr als eine einzelner Wert interessiert, so können wir die Werte in einem Vektor zusammenfassen. \\(X: \\Omega \\rightarrow \\mathbb{R}\\) ist dann eine Abbildung in den \\(\\mathbb{R}^n\\) und statt Mengen \\(B \\in \\mathcal{B}(\\mathbb{R})\\) zu betrachten, müssen wir nun Mengen \\(B^{\\prime} \\in \\mathcal{B}(\\mathbb{R}^n)\\) untersuchen.\n\n\nBeispiel 3.1 Es sei \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum, wobei \\(\\Omega = \\{ 1,2,3,4,5 \\}\\) und \\[\\begin{align*}\n    \\mathcal{F}=\\big\\{ \\emptyset, \\Omega, \\ \\{ 1,2,3,4 \\}, \\ \\{ 3,4,5 \\}, \\ \\{ 5 \\}, \\ \\{ 1,2 \\}, \\ \\{ 1,2,5 \\}, \\ \\{ 3,4 \\} \\big\\}.\n\\end{align*}\\]\n\nDefiniere \\(X:\\Omega \\rightarrow \\mathbb{R}, \\ X(\\omega)= \\omega\\). Dann gilt \\(X^{-1}(\\{ 3 \\})= \\{ 3 \\} \\notin \\mathcal{F}\\) und somit ist \\(X\\) keine Zufallsvariable.\nDefiniere \\(Y:\\Omega \\rightarrow \\mathbb{R}, \\ Y(\\omega)= \\mathbb{1}_{\\{ 3,4,5 \\}}(\\omega)\\) und bestimme die Urbilder \\[\\begin{align*}\n     Y^{-1}(B) =\n     \\begin{cases}\n     \\emptyset &, 0 \\notin B, 1 \\notin B \\\\\n     \\{ 1,2 \\} &, 0 \\in B, 1 \\notin B\\\\\n     \\{ 3,4,5 \\} &, 0 \\notin B, 1 \\in B\\\\\n     \\Omega &, 0 \\in B, 1 \\in B\n     \\end{cases}\n     \\end{align*}\\] für \\(B \\in \\mathcal{B}(\\mathbb{R})\\). Also ist \\(Y\\) eine Zufallsvariable.\n\n\nIn diesen Fällen war es einfach, alle relevanten Urbilder händisch zu bestimmen. Jedoch kann dies für komplizierte Zufallsvariablen anders sein. Praktischerweise gibt es ein Theorem, dass uns direkt die Messbarkeit einer Abbildung \\(X\\) gibt, indem nur eine bestimme Klasse von Urbildern betrachtet wird.\n\nTheorem 3.1 Es sei \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum und \\(X: \\Omega \\rightarrow \\mathbb{R}\\) eine Abbildung auf dem Grundraum in die reelle Zahlen. \\(X\\) ist eine Zufallsvariable genau dann, wenn \\(\\{ \\omega \\in \\Omega \\vert X(\\omega) \\leq x \\} \\in \\mathcal{F}\\) für alle \\(x \\in \\mathbb{R}\\).\n\nÜblicherweise interessiert es uns in der Stochastik gar nicht so sehr, wie die Abbildung \\(X\\) in Abhängigkeit von \\(\\omega \\in \\Omega\\) definiert ist. Tatsächlich untersuchen wir hauptsächlich die Frage, welche Werte die Zufallsvariable annimmt und wie wahrscheinlich dies für konkrete Werte oder ganze Bereiche ist. Konkret begnügen wir uns damit “nur” die so genannte Verteilung von \\(X\\) zu kennen.\n\nDefinition 3.2 (Verteilung) Es sei \\(X\\) eine Zufallsvariable auf dem Wahrscheinlichkeitsraum \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). Die Funktion \\(\\mathbb{P}_X: \\mathcal{B}(\\mathbb{R}) \\rightarrow [0, 1]\\) mit \\[\\begin{align*}\n        \\mathbb{P}_X(B) = \\mathbb{P}(\\{ \\omega \\in \\Omega \\vert X(\\omega) \\in B \\})\n    \\end{align*}\\] heißt Verteilung von \\(X\\).\n\n\nAnmerkung. Zwar kommt die Größe \\(\\omega \\in \\Omega\\) in Definition 3.2 noch formal im Rahmen des Urbildes vor, allerdings werden wir schon bald sehen, dass für viele Klassen von Verteilungen, konkrete Wahrscheinlichkeiten in den Vordergrund und \\(\\omega\\) in den Hintergrund rücken.\n\nInteressanterweise sind die in Theorem 3.1 betrachteten Mengen vollkommen ausreichend, um die Verteilung einer Zufallsvariable komplett zu charakterisieren. Dazu definieren wir uns die Hilfsfunktion\n\nDefinition 3.3 (Verteilungsfunktion) Es sei \\(X\\) eine Zufallsvariable auf dem Wahrscheinlichkeitsraum \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\). Die Verteilungsfunktion \\(F_X: \\mathbb{R} \\rightarrow [0, 1]\\) ist definiert als \\[\\begin{align*}\n        F_X(x)\n        =\n        \\mathbb{P}(\\{ \\omega \\in \\Omega \\vert X(\\omega) \\leq x \\})\n        =\n        \\mathbb{P}(X \\leq x)\n    \\end{align*}\\] für alle \\(x \\in \\mathbb{R}\\).\n\nund nun gilt\n\nTheorem 3.2 Die Verteilung \\(\\mathbb{P}_X\\) einer Zufallsvariablen \\(X\\) wird eindeutig durch deren Verteilungsfunktion \\(F_X\\) charakterisiert.\n\n\nBeispiel 3.2 Nehmen wir an, dass wir einen blauen und einen grünen Würfel haben, die sich abgesehen von der Farbe um nichts unterscheiden. Nun sei \\(G\\) die gewürfelte Augenzahl des grünen Würfels und \\(B\\) die gewürfelte Augenzahl des blauen Würfels. Offensichtlich sind die Verteilungsfunktionen von \\(B\\) und \\(G\\) gleich und wir sprechen davon, dass \\(B\\) und \\(G\\) identisch verteilt sind.\nIntuitiv bedeutet das allerdings nicht, dass \\(B\\) und \\(G\\) immer gleich sind. Schließlich würden wir ja nicht erwarten, dass der blaue und grüne Würfel immer die gleiche Zahl zeigen. Bildlich gesprochen bedeutet die identische Verteilung nur, dass die Histogramme der beiden Würfel sich annähern, je öfter gewürfelt wurde (siehe Abbildung 3.1).\n\n\n\n\n\nAbbildung 3.1: Die Histogramme des grünen und roten Würfels nähern sich an, je öfter man würfelt. Deren Verteilung sind identisch.\n\n\n\n\nWeiterhin überlegt man sich schnell, dass \\(\\mathbb{P}(G \\leq x) = 0\\) für alle \\(x < 1\\), \\(\\mathbb{P}(G \\leq x) = 1\\) für alle \\(x \\geq 6\\) und \\(\\mathbb{P}(G \\leq x) = \\mathbb{P}(G \\leq \\lfloor x \\rfloor)\\) für alle \\(x \\in [1, 6)\\), da \\(G\\) sinnvollerweise nur die Werte \\(x = 1, \\ldots, 6\\) annehmen kann.\nIn dieser Aussage erkennen wir wieder, dass uns die \\(\\omega \\in \\Omega\\) wenig interessieren. Wir brauchen den Ausdruck \\(G(\\omega)\\) nicht konkret definieren, um zu wissen, dass nach Möglichkeit \\(G(\\omega) \\in \\{ 1, \\ldots, 6 \\}\\) für alle \\(\\omega \\in \\Omega\\) sein sollte, wenn \\(G\\) tatsächlich die Augenzahlen des grünen Würfels beschreiben soll.\nAn dieser Stelle stoßen wir allerdings auf eine mathematische Spitzfindigkeit. Auch wenn uns die Rolle des \\(\\omega\\) nicht wirklich interessiert, so wollen wir die Funktion \\(G\\) möglichst wenig einschränken. In diesem Fall können wir die Anforderungen an \\(G\\) noch ein wenig aufweichen und stattdessen fordern, dass \\(G(\\omega)\\) andere Werte annehmen darf, solange die Wahrscheinlichkeit, dass \\(G(\\omega) \\in \\{ 1, \\ldots, 6 \\}\\) gleich 1 ist, also in Symbolen ausgedrückt \\(\\mathbb{P}(G \\in \\{ 1, \\ldots, 6 \\}) = 1\\). Wir sprechen hier davon, dass \\(G\\) fast sicher in \\(\\{ 1, \\ldots, 6 \\}\\) liegt.\nDies bestärkt nochmal die Tatsache, dass uns die \\(\\omega\\) gar nicht so sehr interessieren, da die Funktion \\(R\\) auf einer Menge \\(A\\) machen kann was sie will, solange \\(\\mathbb{P}(A) = 0\\). Dies ist am Anfang zunächst etwas gewöhnungsbedürftig, bietet aber im späteren Verlauf einige Vorteile.\nAbschließend berechnen wir noch anhand des Beispiels \\(\\mathbb{P}(G \\leq 2.4) = \\mathbb{P}(G = 1) + \\mathbb{P}(G = 2)\\) und aus der Tatsache, dass \\(\\mathbb{P}(G = k) = \\frac{1}{6}\\) für alle \\(k \\in \\{ 1, \\ldots, 6 \\}\\) und \\(\\mathbb{P}(G = k) = 0\\) sonst, dass \\(\\mathbb{P}(G \\leq x) = \\frac{\\lfloor x \\rfloor}{6}\\) für alle \\(x \\in [1, 6)\\). Zusammenfassend haben wir also \\[\\begin{align*}\n    F_G(x)\n    =\n    \\mathbb{P}(G \\leq x)\n    =\n    \\begin{cases}\n        0 &, x < 1 \\\\\n        \\frac{\\lfloor x \\rfloor}{6} &, 1 \\leq x < 6\\\\\n        1 &, x \\geq 1\n    \\end{cases}.\n\\end{align*}\\]\n\n\n\n\n\nAbbildung 3.2: Verteilungsfunktion eines Würfels\n\n\n\n\n\n\n\n\n\n\nDer Vollständigkeit halber noch ein Theorem bzgl. den Eigenschaften einer Verteilungsfunktion und der Existenz einer entsprechenden Zufallsvariable.\n\nTheorem 3.3 Es gelten die folgenden zwei Aussagen.\n\nEs sei \\(X\\) eine beliebige Zufallsvariable. Dann besitzt deren Verteilungsfunktion \\(F_X: \\mathbb{R} \\rightarrow [0, 1]\\) die Eigenschaften\n\nAsymptotik: \\(\\lim\\limits_{x \\rightarrow -\\infty} F_X(x) = 0, \\lim\\limits_{x \\rightarrow \\infty} F_X(x) = 1\\).\nMonotonie: \\(F_X(x) \\leq F_X(x + h)\\) für alle \\(x \\in \\mathbb{R}\\) und \\(h \\geq 0\\).\nRechtsseitige Stetigkeit: \\(\\lim\\limits_{x \\rightarrow x_0+0} F_X(x) = F_X(x_0)\\) für alle \\(x \\in \\mathbb{R}\\).\n\nErfüllt eine Funktion \\(F: \\mathbb{R} \\rightarrow [0, 1]\\) die Eigenschaften 1 bis 3, so existiert ein Wahrscheinlichkeitsraum \\((\\Omega,\\mathcal{F}, \\mathbb{P})\\) und eine Zufallsvariable \\(X\\) auf diesem Wahrscheinlichkeitsraum dessen Verteilungsfunktion \\(F\\) ist.\n\n\n\n\n\n\n\nsiehe Wikipedia.↩︎\nno pun intended↩︎"
  },
  {
    "objectID": "bibliografie.html",
    "href": "bibliografie.html",
    "title": "Bibliografie",
    "section": "",
    "text": "Eddy, David M. 1982. “Probabilistic Reasoning in Clinical\nMedicine: Problems and Opportunities.” In Judgment Under\nUncertainty: Heuristics and Biases, edited by Daniel Kahneman, Paul\nSlovic, and AmosEditors Tversky, 249–67. Cambridge University Press. https://doi.org/10.1017/CBO9780511809477.019.\n\n\nSpodarev, Evgeny. 2018. Vorlesungsskript Zur Elementaren\nWahrscheinlichkeitsrechnung Und Statistik.\n\n\n———. 2020. Vorlesungsskript Zur Elementaren\nWahrscheinlichkeitsrechnung Und Stastistik."
  }
]